{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46121bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these at the top of your notebook cell\n",
    "import matplotlib\n",
    "matplotlib.use('inline')  # or 'Agg'\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()  # Turn on interactive mode\n",
    "\n",
    "# Also add this to force display\n",
    "%matplotlib inline\n",
    "import torchvision.transforms.v2 as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f532abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "from typing import Tuple, Optional, List, Dict, Iterator\n",
    "import logging\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class IMCDataset(Dataset):\n",
    "    \"\"\"Dataset for IMC (Imaging Mass Cytometry) data for tissue type and condition prediction\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        use_mask: bool = False,\n",
    "        channels: Optional[List[int]] = None,\n",
    "        image_size: Optional[Tuple[int, int]] = None,\n",
    "        normalize: bool = True,\n",
    "        arcsinh_transform: bool = True,\n",
    "        cofactor: float = 5.0,\n",
    "        classification_task: str = \"condition\",  # \"condition\" (Benign vs Malignant) - \"tissue\" and \"both\" removed since we only have prostate data\n",
    "        split: str = \"train\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: Directory containing ROI folders\n",
    "            transform: Optional transform to be applied on images\n",
    "            target_transform: Optional transform to be applied on labels\n",
    "            use_mask: Whether to use the mask.tiff files\n",
    "            channels: List of channel indices to use (if None, uses all)\n",
    "            image_size: Size to resize images to (height, width)\n",
    "            normalize: Whether to normalize channels\n",
    "            arcsinh_transform: Whether to apply arcsinh transformation\n",
    "            cofactor: Cofactor for arcsinh transformation\n",
    "            classification_task: What to predict - \"tissue\", \"condition\", or \"both\"\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.use_mask = use_mask\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.normalize = normalize\n",
    "        self.arcsinh_transform = arcsinh_transform\n",
    "        self.cofactor = cofactor\n",
    "        self.classification_task = classification_task\n",
    "        \n",
    "        # Scan directory and parse folder names\n",
    "        self.samples = self._scan_directory()\n",
    "        \n",
    "        # Create label mappings based on classification task\n",
    "        self._create_label_mappings()\n",
    "        \n",
    "        logging.info(f\"Loaded {len(self.samples)} samples\")\n",
    "        logging.info(f\"Classification task: {self.classification_task}\")\n",
    "        logging.info(f\"Labels: {self.unique_labels}\")\n",
    "\n",
    "        # Set transforms if not provided\n",
    "        if transform is None and image_size is not None:\n",
    "            train_transform, val_transform = self.get_imc_transforms(image_size)\n",
    "            self.transform = train_transform if split == \"train\" else val_transform\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        \n",
    "    def _scan_directory(self):\n",
    "        \"\"\"Scan directory for ROI folders and parse information\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        for roi_folder in self.data_dir.glob(\"ROI*\"):\n",
    "            if not roi_folder.is_dir():\n",
    "                continue\n",
    "                \n",
    "            # Parse folder name: ROI###_TISSUE_[Benign_]TMA###[N]\n",
    "            folder_name = roi_folder.name\n",
    "            \n",
    "            # Extract ROI number\n",
    "            roi_match = re.match(r\"ROI(\\d+)\", folder_name)\n",
    "            if not roi_match:\n",
    "                continue\n",
    "            roi_num = int(roi_match.group(1))\n",
    "            \n",
    "            # Extract tissue type\n",
    "            parts = folder_name.split('_')\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            tissue = parts[1]  # PROSTATE, LIVER, KIDNEY\n",
    "            \n",
    "            # Determine if benign or malignant\n",
    "            if \"Benign\" in folder_name:\n",
    "                condition = \"Benign\"\n",
    "            else:\n",
    "                condition = \"Malignant\"\n",
    "            \n",
    "            # Check if image files exist\n",
    "            imc_path = roi_folder / \"input\" / \"imc\"\n",
    "            if not imc_path.exists():\n",
    "                continue\n",
    "                \n",
    "            # Look for .ome.tiff file\n",
    "            ome_files = list(imc_path.glob(\"*.ome.tiff\"))\n",
    "            if not ome_files:\n",
    "                continue\n",
    "            image_file = ome_files[0]\n",
    "            \n",
    "            # Look for mask file if needed\n",
    "            mask_file = None\n",
    "            if self.use_mask:\n",
    "                mask_files = list(imc_path.glob(\"*_mask.tiff\"))\n",
    "                if mask_files:\n",
    "                    mask_file = mask_files[0]\n",
    "            \n",
    "            samples.append({\n",
    "                'roi_num': roi_num,\n",
    "                'tissue': tissue,\n",
    "                'condition': condition,\n",
    "                'folder_name': folder_name,\n",
    "                'image_path': image_file,\n",
    "                'mask_path': mask_file,\n",
    "                'roi_folder': roi_folder\n",
    "            })\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def _create_label_mappings(self):\n",
    "        \"\"\"Create label mappings based on classification task\"\"\"\n",
    "        if self.classification_task == \"tissue\":\n",
    "            labels = [sample['tissue'] for sample in self.samples]\n",
    "        elif self.classification_task == \"condition\":\n",
    "            labels = [sample['condition'] for sample in self.samples]\n",
    "        elif self.classification_task == \"both\":\n",
    "            labels = [f\"{sample['tissue']}_{sample['condition']}\" for sample in self.samples]\n",
    "        else:\n",
    "            raise ValueError(\"classification_task must be 'tissue', 'condition', or 'both'\")\n",
    "        \n",
    "        self.unique_labels = sorted(list(set(labels)))\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.unique_labels)}\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = self._load_image(sample['image_path'])\n",
    "        \n",
    "        # Load mask if needed\n",
    "        mask = None\n",
    "        if self.use_mask and sample['mask_path']:\n",
    "            mask = self._load_mask(sample['mask_path'])\n",
    "        \n",
    "        # Get label based on classification task\n",
    "        if self.classification_task == \"tissue\":\n",
    "            label = sample['tissue']\n",
    "        elif self.classification_task == \"condition\":\n",
    "            label = sample['condition']\n",
    "        elif self.classification_task == \"both\":\n",
    "            label = f\"{sample['tissue']}_{sample['condition']}\"\n",
    "        \n",
    "        label_idx = self.label_to_idx[label]\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            label_idx = self.target_transform(label_idx)\n",
    "        \n",
    "        if mask is not None:\n",
    "            return image, label_idx, mask\n",
    "        else:\n",
    "            return image, label_idx\n",
    "    \n",
    "    def _load_image(self, img_path: Path) -> torch.Tensor:\n",
    "        \"\"\"Load and preprocess IMC image\"\"\"\n",
    "        # Load OME-TIFF image\n",
    "        img = tifffile.imread(str(img_path))\n",
    "        \n",
    "        # Ensure image is float32\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        # Handle different image shapes\n",
    "        if img.ndim == 2:\n",
    "            # Single channel image\n",
    "            img = img[np.newaxis, ...]  # Add channel dimension\n",
    "        elif img.ndim == 3:\n",
    "            # Multi-channel image - OME-TIFF usually has channels first\n",
    "            # If channels are last, transpose\n",
    "            if img.shape[2] < img.shape[0]:\n",
    "                img = np.transpose(img, (2, 0, 1))\n",
    "        \n",
    "        # Select specific channels if specified\n",
    "        if self.channels is not None:\n",
    "            img = img[self.channels]\n",
    "        \n",
    "        # Apply arcsinh transformation (common for mass cytometry data)\n",
    "        if self.arcsinh_transform:\n",
    "            img = np.arcsinh(img / self.cofactor)\n",
    "        \n",
    "        # Normalize each channel\n",
    "        if self.normalize:\n",
    "            for c in range(img.shape[0]):\n",
    "                channel = img[c]\n",
    "                if channel.std() > 0:\n",
    "                    img[c] = (channel - channel.mean()) / channel.std()\n",
    "        \n",
    "        # Resize if needed\n",
    "        if self.image_size is not None and self.image_size != img.shape[1:]:\n",
    "            img = torch.nn.functional.interpolate(\n",
    "                torch.from_numpy(img).unsqueeze(0),\n",
    "                size=self.image_size,\n",
    "                mode='bilinear',\n",
    "                align_corners=False\n",
    "            ).squeeze(0).numpy()\n",
    "        \n",
    "        return torch.from_numpy(img)\n",
    "    \n",
    "    def get_imc_transforms(self, image_size: Tuple[int, int]):\n",
    "        \"\"\"\n",
    "        Get transforms for IMC data\n",
    "        \n",
    "        Args:\n",
    "            image_size: Target image size (height, width)\n",
    "        \n",
    "        Returns:\n",
    "            train_transform, val_transform\n",
    "        \"\"\"\n",
    "        \n",
    "        # Training transforms with augmentation\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation([-90,90]),\n",
    "            transforms.RandomAffine(degrees=[-45,45], translate=[0.05, 0.05]),\n",
    "            transforms.Resize(image_size, antialias=True),\n",
    "        ])\n",
    "        \n",
    "        # Validation transforms (no augmentation)\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize(image_size, antialias=True),\n",
    "        ])\n",
    "        \n",
    "        return train_transform, val_transform\n",
    "    \n",
    "    def _load_mask(self, mask_path: Path) -> torch.Tensor:\n",
    "        \"\"\"Load segmentation mask\"\"\"\n",
    "        mask = tifffile.imread(str(mask_path))\n",
    "        return torch.from_numpy(mask.astype(np.int64))\n",
    "    \n",
    "    def get_class_weights(self, indices: Optional[List[int]] = None):\n",
    "        \"\"\"Calculate class weights for imbalanced datasets\"\"\"\n",
    "       \n",
    "        if indices is not None and len(indices) > 0:\n",
    "                # Convert to list if it's a numpy array or tensor\n",
    "                if hasattr(indices, 'tolist'):\n",
    "                    indices = indices.tolist()\n",
    "                elif isinstance(indices, (np.ndarray, torch.Tensor)):\n",
    "                    indices = indices.tolist()\n",
    "        \n",
    "                samples_to_use = [self.samples[i] for i in indices]\n",
    "        else:\n",
    "                samples_to_use = self.samples\n",
    "\n",
    "\n",
    "        \n",
    "        if self.classification_task == \"tissue\":\n",
    "            labels = [sample['tissue'] for sample in samples_to_use]\n",
    "        elif self.classification_task == \"condition\":\n",
    "            labels = [sample['condition'] for sample in samples_to_use]\n",
    "        elif self.classification_task == \"both\":\n",
    "            labels = [f\"{sample['tissue']}_{sample['condition']}\" for sample in samples_to_use]\n",
    "        \n",
    "        from collections import Counter\n",
    "        label_counts = Counter(labels)\n",
    "        total_samples = len(samples_to_use)\n",
    "        \n",
    "        weights = []\n",
    "        for label in self.unique_labels:\n",
    "            if label in label_counts:\n",
    "                weight = total_samples / (len(self.unique_labels) * label_counts[label])\n",
    "            else:\n",
    "                weight = 0.0  # Class not present in this fold\n",
    "            weights.append(weight)\n",
    "        \n",
    "        return torch.FloatTensor(weights)\n",
    "    \n",
    "    \n",
    "\n",
    "def create_kfold_dataloaders(\n",
    "    data_dir: str,\n",
    "    k_folds: int = 5,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 4,\n",
    "    pin_memory: bool = True,\n",
    "    random_seed: int = 17025,\n",
    "    **dataset_kwargs\n",
    ") -> Tuple[Iterator[Tuple[DataLoader, DataLoader, Dict]], Dict]:\n",
    "    \"\"\"\n",
    "    Create k-fold cross-validation dataloaders\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing ROI folders\n",
    "        k_folds: Number of folds for cross-validation\n",
    "        batch_size: Batch size for dataloaders\n",
    "        num_workers: Number of workers for dataloaders\n",
    "        pin_memory: Whether to pin memory\n",
    "        random_seed: Random seed for reproducibility\n",
    "        **dataset_kwargs: Additional arguments for IMCDataset\n",
    "    \n",
    "    Returns:\n",
    "        Iterator yielding (train_loader, val_loader, fold_info) for each fold\n",
    "        Overall dataset info dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create full dataset\n",
    "    full_dataset = IMCDataset(\n",
    "        data_dir=data_dir,\n",
    "        **dataset_kwargs\n",
    "    )\n",
    "    \n",
    "    # Check if we have any samples\n",
    "    if len(full_dataset) == 0:\n",
    "        raise ValueError(\"No valid samples found\")\n",
    "    \n",
    "    # Validate k_folds parameter\n",
    "    if k_folds < 2:\n",
    "        raise ValueError(\"k_folds must be at least 2\")\n",
    "    if k_folds > len(full_dataset):\n",
    "        raise ValueError(f\"k_folds ({k_folds}) cannot be greater than number of samples ({len(full_dataset)})\")\n",
    "    \n",
    "    # Get labels for stratification\n",
    "    if full_dataset.classification_task == \"tissue\":\n",
    "        labels = [sample['tissue'] for sample in full_dataset.samples]\n",
    "    elif full_dataset.classification_task == \"condition\":\n",
    "        labels = [sample['condition'] for sample in full_dataset.samples]\n",
    "    else:\n",
    "        labels = [f\"{sample['tissue']}_{sample['condition']}\" for sample in full_dataset.samples]\n",
    "    \n",
    "    # Check class distribution\n",
    "    from collections import Counter\n",
    "    class_counts = Counter(labels)\n",
    "    min_class_count = min(class_counts.values())\n",
    "    \n",
    "    print(f\" Class distribution: {dict(class_counts)}\")\n",
    "    \n",
    "    if min_class_count < k_folds:\n",
    "        print(f\" Warning: Smallest class has only {min_class_count} samples, but k_folds={k_folds}\")\n",
    "        print(\"   Consider reducing k_folds or this may cause stratification issues\")\n",
    "    \n",
    "    # Create stratified k-fold splits\n",
    "    try:\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=random_seed)\n",
    "        indices = np.array(range(len(full_dataset)))\n",
    "        labels_array = np.array(labels)\n",
    "        \n",
    "        fold_splits = list(skf.split(indices, labels_array))\n",
    "        print(f\" Using stratified {k_folds}-fold cross-validation\")\n",
    "        \n",
    "    except (ImportError, ValueError) as e:\n",
    "        # Fall back to regular k-fold if sklearn not available or stratification fails\n",
    "        print(f\" Stratified split failed ({e}), using regular {k_folds}-fold split\")\n",
    "        \n",
    "        # Manual k-fold implementation\n",
    "        torch.manual_seed(random_seed)\n",
    "        indices = torch.randperm(len(full_dataset)).tolist()\n",
    "        fold_size = len(full_dataset) // k_folds\n",
    "        \n",
    "        fold_splits = []\n",
    "        for i in range(k_folds):\n",
    "            start_idx = i * fold_size\n",
    "            end_idx = (i + 1) * fold_size if i < k_folds - 1 else len(full_dataset)\n",
    "            \n",
    "            val_indices = indices[start_idx:end_idx]\n",
    "            train_indices = indices[:start_idx] + indices[end_idx:]\n",
    "            \n",
    "            fold_splits.append((train_indices, val_indices))\n",
    "    \n",
    "    # Overall dataset info\n",
    "    overall_info = {\n",
    "        'num_classes': len(full_dataset.unique_labels),\n",
    "        'class_names': full_dataset.unique_labels,\n",
    "        'total_samples': len(full_dataset),\n",
    "        'classification_task': full_dataset.classification_task,\n",
    "        'k_folds': k_folds\n",
    "    }\n",
    "    \n",
    "    def fold_generator():\n",
    "        \"\"\"Generator that yields train/val loaders for each fold\"\"\"\n",
    "        \n",
    "        for fold_idx, (train_indices, val_indices) in enumerate(fold_splits):\n",
    "            print(f\"\\n Fold {fold_idx + 1}/{k_folds}\")\n",
    "            \n",
    "            # Create datasets for this fold with appropriate transforms\n",
    "            train_dataset_kwargs = {**dataset_kwargs, 'split': 'train'}\n",
    "            val_dataset_kwargs = {**dataset_kwargs, 'split': 'val'}\n",
    "            \n",
    "            # Remove 'split' from kwargs if it was passed in originally\n",
    "            train_dataset_kwargs.pop('split', None)\n",
    "            val_dataset_kwargs.pop('split', None)\n",
    "            \n",
    "            train_dataset_full = IMCDataset(data_dir=data_dir, split='train', **train_dataset_kwargs)\n",
    "            val_dataset_full = IMCDataset(data_dir=data_dir, split='val', **val_dataset_kwargs)\n",
    "            \n",
    "            # Create subsets for this fold\n",
    "            train_dataset = torch.utils.data.Subset(train_dataset_full, train_indices)\n",
    "            val_dataset = torch.utils.data.Subset(val_dataset_full, val_indices)\n",
    "            \n",
    "            # Create dataloaders\n",
    "            train_loader = DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory,\n",
    "                drop_last=True\n",
    "            )\n",
    "            \n",
    "            val_loader = DataLoader(\n",
    "                val_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory,\n",
    "                drop_last=False\n",
    "            )\n",
    "            \n",
    "            # Calculate class weights for this fold\n",
    "            class_weights = full_dataset.get_class_weights(train_indices)\n",
    "            \n",
    "            # Get class distribution for this fold\n",
    "            train_labels = [labels[i] for i in train_indices]\n",
    "            val_labels = [labels[i] for i in val_indices]\n",
    "            \n",
    "            from collections import Counter\n",
    "            train_dist = Counter(train_labels)\n",
    "            val_dist = Counter(val_labels)\n",
    "            \n",
    "            fold_info = {\n",
    "                'fold_idx': fold_idx,\n",
    "                'train_size': len(train_indices),\n",
    "                'val_size': len(val_indices),\n",
    "                'class_weights': class_weights,\n",
    "                'train_distribution': dict(train_dist),\n",
    "                'val_distribution': dict(val_dist)\n",
    "            }\n",
    "            \n",
    "            # Print fold summary\n",
    "            print(f\"   Train samples: {fold_info['train_size']}\")\n",
    "            print(f\"   Val samples: {fold_info['val_size']}\")\n",
    "            print(f\"   Train distribution: {fold_info['train_distribution']}\")\n",
    "            print(f\"   Val distribution: {fold_info['val_distribution']}\")\n",
    "            \n",
    "            yield train_loader, val_loader, fold_info\n",
    "    \n",
    "    # Print overall summary\n",
    "    print(f\"ðŸ“Š K-Fold Dataset Summary:\")\n",
    "    print(f\"   Classification task: {overall_info['classification_task']}\")\n",
    "    print(f\"   Classes: {overall_info['class_names']}\")\n",
    "    print(f\"   Total samples: {overall_info['total_samples']}\")\n",
    "    print(f\"   Number of folds: {overall_info['k_folds']}\")\n",
    "    \n",
    "    return fold_generator(), overall_info\n",
    "\n",
    "\n",
    "def create_single_fold_dataloaders(\n",
    "    data_dir: str,\n",
    "    fold_idx: int,\n",
    "    k_folds: int = 5,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 4,\n",
    "    pin_memory: bool = True,\n",
    "    random_seed: int = 17025,\n",
    "    **dataset_kwargs\n",
    ") -> Tuple[DataLoader, DataLoader, Dict]:\n",
    "    \"\"\"\n",
    "    Create dataloaders for a specific fold (useful for parallel processing)\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing ROI folders\n",
    "        fold_idx: Which fold to create (0-indexed)\n",
    "        k_folds: Total number of folds\n",
    "        **other args: Same as create_kfold_dataloaders\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, val_loader, fold_info for the specified fold\n",
    "    \"\"\"\n",
    "    \n",
    "    fold_generator, overall_info = create_kfold_dataloaders(\n",
    "        data_dir=data_dir,\n",
    "        k_folds=k_folds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        random_seed=random_seed,\n",
    "        **dataset_kwargs\n",
    "    )\n",
    "    \n",
    "    # Get the specific fold\n",
    "    for i, (train_loader, val_loader, fold_info) in enumerate(fold_generator):\n",
    "        if i == fold_idx:\n",
    "            return train_loader, val_loader, fold_info\n",
    "    \n",
    "    raise ValueError(f\"Fold {fold_idx} not found (max fold index: {k_folds-1})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3364e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using EfficientNet-B3 backbone (pretrained=True)\n",
      "Simple Model Summary\n",
      "Markers: 62, Backbone: EfficientNet-B3, pretrained: True\n",
      "Feature_dim: 64, classes: 2, device: cuda\n",
      "Dropout rate: 0.6\n",
      "Total parameters: 11,551,706\n",
      "Trainable parameters: 11,551,706\n"
     ]
    }
   ],
   "source": [
    "from sympy import Ge\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.ops import DropBlock2d\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "\n",
    "class EfficientNetMarkerEncoder(nn.Module):\n",
    "    \"\"\"EfficientNet-B3 based marker encoder for individual IMC marker channels\"\"\"\n",
    "    def __init__(self, feature_dim: int = 128, pretrained: bool = True, dropout_rate: float = 0.3):\n",
    "        super(EfficientNetMarkerEncoder, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # Load the pretrained EfficientNet-B3 model\n",
    "        if pretrained:\n",
    "            weights = models.EfficientNet_B3_Weights.DEFAULT\n",
    "        else:\n",
    "            weights = None\n",
    "            \n",
    "        self.backbone = models.efficientnet_b3(weights=weights)\n",
    "        \n",
    "        # EfficientNet-B3 output features from the last layer before classifier\n",
    "        # EfficientNet classifier is a Sequential with a Dropout and Linear layer\n",
    "        backbone_out_features = self.backbone.classifier[1].in_features  # 1792 for EfficientNet-B4\n",
    "        \n",
    "        # Modify the first layer to accept a single channel input\n",
    "        original_first_conv = self.backbone.features[0][0]\n",
    "        self.backbone.features[0][0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=original_first_conv.out_channels,\n",
    "            kernel_size=original_first_conv.kernel_size,\n",
    "            stride=original_first_conv.stride,\n",
    "            padding=original_first_conv.padding,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        # Remove final classification layers but keep the avgpool and flatten\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        # Store the avgpool and flatten operations explicitly\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Adding custom feature head\n",
    "        self.feature_head = nn.Sequential(\n",
    "            nn.LayerNorm(backbone_out_features),\n",
    "            nn.Linear(backbone_out_features, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, feature_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 1, H, W]\n",
    "        # Extract features from backbone (before classifier)\n",
    "        features = self.backbone.features(x)  # [batch_size, 1792, H', W']\n",
    "        features = self.avgpool(features)  # [batch_size, 1792, 1, 1]\n",
    "        features = self.flatten(features)  # [batch_size, 1792]\n",
    "        features = self.feature_head(features)\n",
    "        return features\n",
    "\n",
    "\n",
    "class SimpleFusionHead(nn.Module):\n",
    "    \"\"\"Simple fusion head using average pooling instead of attention\"\"\"\n",
    "    def __init__(self, feature_dim=128, num_markers=62, num_classes=2, dropout_rate=0.5):\n",
    "        super(SimpleFusionHead, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_markers = num_markers\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Simple classifier with more dropout for regularization\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(feature_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.GELU(),                        \n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, marker_features):\n",
    "        # marker_features = [batch_size, num_markers, feature_dim]\n",
    "        # Simple average pooling across markers\n",
    "        pooled_features = torch.mean(marker_features, dim=1)  # [batch_size, feature_dim]\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'pooled_features': pooled_features\n",
    "        }\n",
    "\n",
    "\n",
    "class SimpleIMCClassifier(nn.Module):\n",
    "    \"\"\"Simplified IMC Classifier with EfficientNet-B3 backbone\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_markers=62,\n",
    "            feature_dim=128,\n",
    "            num_classes=2,\n",
    "            pretrained=True,\n",
    "            dropout_rate=0.5,\n",
    "            shared_backbone=True\n",
    "    ):\n",
    "        super(SimpleIMCClassifier, self).__init__()\n",
    "        self.num_markers = num_markers\n",
    "        self.feature_dim = feature_dim\n",
    "        self.shared_backbone = shared_backbone\n",
    "\n",
    "        # Create the encoder\n",
    "        if shared_backbone:\n",
    "            self.marker_encoder = EfficientNetMarkerEncoder(\n",
    "                feature_dim=feature_dim,\n",
    "                pretrained=pretrained,\n",
    "                dropout_rate=dropout_rate\n",
    "            )\n",
    "            print(f\"Using EfficientNet-B3 backbone (pretrained={pretrained})\")\n",
    "        else:\n",
    "            # For separate backbones (not implemented)\n",
    "            pass\n",
    "        \n",
    "        # Simple Fusion head\n",
    "        self.fusion_head = SimpleFusionHead(\n",
    "            feature_dim=feature_dim,\n",
    "            num_markers=num_markers,\n",
    "            num_classes=num_classes,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "\n",
    "    def forward(self, imc_data):\n",
    "        # imc_data shape: [batch_size, num_markers, H, W]\n",
    "        batch_size, num_markers, H, W = imc_data.shape\n",
    "        assert num_markers == self.num_markers, f\"Expected {self.num_markers}, got {num_markers}\"\n",
    "        \n",
    "        # Extract features from each marker using EfficientNet-B3\n",
    "        marker_features = []\n",
    "        for i in range(num_markers):\n",
    "            # Get single marker data: [batch_size, 1, H, W]\n",
    "            marker_data = imc_data[:, i:i+1, :, :]\n",
    "            if self.shared_backbone:\n",
    "                features = self.marker_encoder(marker_data)\n",
    "            else:\n",
    "                pass  # Not implemented\n",
    "            marker_features.append(features)\n",
    "\n",
    "        # Stack features: [batch_size, num_markers, feature_dim]\n",
    "        marker_features = torch.stack(marker_features, dim=1)\n",
    "\n",
    "        # Fusion and classification\n",
    "        output = self.fusion_head(marker_features)\n",
    "        return output\n",
    "\n",
    "    def freeze_backbones(self):\n",
    "        \"\"\"Freeze EfficientNet-B3 backbones and only train Fusion Head\"\"\"\n",
    "        if self.shared_backbone:\n",
    "            for param in self.marker_encoder.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        print(\"Frozen backbone - only training fusion head\")\n",
    "\n",
    "    def unfreeze_backbones(self):\n",
    "        \"\"\"Unfreeze EfficientNet-B3 backbone for fine tuning\"\"\"\n",
    "        if self.shared_backbone:\n",
    "            for param in self.marker_encoder.backbone.parameters():\n",
    "                param.requires_grad = True\n",
    "        print(\"Unfrozen EfficientNet-B3 backbones - training full model\")\n",
    "\n",
    "\n",
    "def create_simple_model(\n",
    "        num_markers=62,\n",
    "        num_classes=2,\n",
    "        feature_dim=128,\n",
    "        pretrained=True,\n",
    "        shared_backbone=True,\n",
    "        dropout_rate=0.5,\n",
    "        device='cuda' if torch.cuda.is_available() else 'mps'\n",
    "):\n",
    "    \"\"\"Create simplified model with EfficientNet-B3 backbone\"\"\"\n",
    "    if not shared_backbone:\n",
    "        print(f\"separate backbones not implemented, using shared\")\n",
    "        shared_backbone = True\n",
    "\n",
    "    model = SimpleIMCClassifier(\n",
    "        num_markers=num_markers,\n",
    "        num_classes=num_classes,\n",
    "        feature_dim=feature_dim,\n",
    "        pretrained=pretrained,\n",
    "        shared_backbone=shared_backbone,\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(\"Simple Model Summary\")\n",
    "    print(f\"Markers: {num_markers}, Backbone: EfficientNet-B3, pretrained: {pretrained}\")\n",
    "    print(f\"Feature_dim: {feature_dim}, classes: {num_classes}, device: {device}\")\n",
    "    print(f\"Dropout rate: {dropout_rate}\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    return model\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "# Create simplified model\n",
    "model = create_simple_model(\n",
    "    num_markers=62,\n",
    "    num_classes=2,  # Update this based on your dataset_info\n",
    "    pretrained=True,\n",
    "    shared_backbone=True,\n",
    "    feature_dim=64,  # Reduced feature dimension\n",
    "    dropout_rate=0.6,  # Higher dropout for regularization\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013cc3b",
   "metadata": {},
   "source": [
    "## Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc5b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebde783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# First, let's fix your IMCTrainer class (there were some bugs)\n",
    "class IMCTrainer:\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            fold_info,  # Added fold_info parameter\n",
    "            dataset_info,\n",
    "            device='cuda' if torch.cuda.is_available() else 'mps',\n",
    "            learning_rate=1e-3,  # Fixed: was 1e3 (too high!)\n",
    "            weight_decay=1e-4,   # Fixed: was 1e4 (too high!)\n",
    "            use_class_weights=True,\n",
    "            use_mixed_precision=True,\n",
    "            save_dir='./checkpoints'\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.fold_info = fold_info  # Store fold information\n",
    "        self.dataset_info = dataset_info\n",
    "        self.device = device\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Loss function\n",
    "        if use_class_weights and 'class_weights' in fold_info:\n",
    "            class_weights = fold_info['class_weights'].to(device)\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "            print(f\"Using class weights: {class_weights}\")\n",
    "        else:\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Mixed precision training for memory efficiency\n",
    "        self.use_mixed_precision = use_mixed_precision\n",
    "        if use_mixed_precision:\n",
    "            self.scaler = torch.amp.GradScaler(\"cuda\")\n",
    "            print(\"Using mixed precision training\") \n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_acc': [],\n",
    "            'learning_rates': []\n",
    "        }\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_model_path = None\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0  # Fixed: was missing\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=\"Training\")\n",
    "        for batch_idx, (images, labels) in enumerate(pbar):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "        \n",
    "            if self.use_mixed_precision:\n",
    "                with torch.amp.autocast(\"cuda\"):\n",
    "                    output = self.model(images)\n",
    "                    loss = self.criterion(output['logits'], labels)\n",
    "\n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                output = self.model(images)\n",
    "                loss = self.criterion(output['logits'], labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate predictions\n",
    "            _, preds = torch.max(output['logits'], 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f\"{loss.item():.4f}\",\n",
    "                'Acc': f\"{accuracy_score(all_labels, all_preds):.4f}\"\n",
    "            })\n",
    "            \n",
    "        epoch_loss = running_loss / len(self.train_loader)\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(self.val_loader, desc=\"Validation\")\n",
    "            for images, labels in pbar:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                if self.use_mixed_precision:\n",
    "                    with torch.amp.autocast(\"cuda\"):\n",
    "                        output = self.model(images)\n",
    "                        loss = self.criterion(output['logits'], labels)\n",
    "                else:\n",
    "                    output = self.model(images)\n",
    "                    loss = self.criterion(output['logits'], labels)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # Calculate predictions\n",
    "                _, preds = torch.max(output['logits'], 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                pbar.set_postfix({'Loss': f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.val_loader)\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "        \n",
    "        # Calculate detailed metrics\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='weighted'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'loss': epoch_loss,\n",
    "            'accuracy': epoch_acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'predictions': all_preds,\n",
    "            'labels': all_labels\n",
    "        }\n",
    "    \n",
    "    def train(self, num_epochs=50, freeze_backbone_epochs=5):\n",
    "        \"\"\"Full training loop\"\"\"\n",
    "        print(f\"Starting training for {num_epochs} epochs\")\n",
    "        print(f\"First {freeze_backbone_epochs} epochs with frozen backbone\")\n",
    "\n",
    "        # Phase 1: Training only the fusion head first with frozen backbone\n",
    "        if freeze_backbone_epochs > 0:\n",
    "            print(f\"Training fusion head only {freeze_backbone_epochs} epochs\")\n",
    "            self.model.freeze_backbones()\n",
    "\n",
    "            for epoch in range(freeze_backbone_epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{freeze_backbone_epochs}\")\n",
    "\n",
    "                # Train \n",
    "                train_loss, train_acc = self.train_epoch()\n",
    "\n",
    "                # Validate\n",
    "                val_results = self.validate_epoch()\n",
    "\n",
    "                # Update history\n",
    "                self.history['train_loss'].append(train_loss)\n",
    "                self.history['val_loss'].append(val_results['loss'])\n",
    "                self.history['train_acc'].append(train_acc)\n",
    "                self.history['val_acc'].append(val_results['accuracy'])\n",
    "                self.history['learning_rates'].append(self.optimizer.param_groups[0]['lr'])\n",
    "\n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "                print(f\"Val Loss: {val_results['loss']:.4f}, Val Acc: {val_results['accuracy']:.4f}\")\n",
    "                print(f\"Val F1: {val_results['f1']:.4f}\")\n",
    "            \n",
    "                # Save best model\n",
    "                if val_results['accuracy'] > self.best_val_acc:\n",
    "                    self.best_val_acc = val_results['accuracy']\n",
    "                    self.save_checkpoint(epoch, f\"best_frozen_epoch_{epoch+1}.pth\", val_results)\n",
    "            \n",
    "                # Learning rate scheduling\n",
    "                self.scheduler.step(val_results['loss'])\n",
    "\n",
    "        # Phase 2: Unfreeze and fine tune complete model\n",
    "        remaining_epochs = num_epochs - freeze_backbone_epochs\n",
    "        if remaining_epochs > 0:\n",
    "            print(f\"Phase 2: fine tuning entire model ({remaining_epochs} epochs)\")\n",
    "            self.model.unfreeze_backbones()\n",
    "\n",
    "            # Reduce lr for fine tuning\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] *= 0.1\n",
    "            print(f\"ðŸ”½ Reduced learning rate to {self.optimizer.param_groups[0]['lr']}\")\n",
    "        \n",
    "            for epoch in range(freeze_backbone_epochs, num_epochs):\n",
    "                print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "                \n",
    "                # Train\n",
    "                train_loss, train_acc = self.train_epoch()\n",
    "                \n",
    "                # Validate\n",
    "                val_results = self.validate_epoch()\n",
    "                \n",
    "                # Update history\n",
    "                self.history['train_loss'].append(train_loss)\n",
    "                self.history['val_loss'].append(val_results['loss'])\n",
    "                self.history['train_acc'].append(train_acc)\n",
    "                self.history['val_acc'].append(val_results['accuracy'])\n",
    "                self.history['learning_rates'].append(self.optimizer.param_groups[0]['lr'])\n",
    "                \n",
    "                print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "                print(f\"Val Loss: {val_results['loss']:.4f}, Val Acc: {val_results['accuracy']:.4f}\")\n",
    "                print(f\"Val F1: {val_results['f1']:.4f}\")\n",
    "                \n",
    "                # Save best model\n",
    "                if val_results['accuracy'] > self.best_val_acc:\n",
    "                    self.best_val_acc = val_results['accuracy']\n",
    "                    self.save_checkpoint(epoch, f\"best_finetuned_epoch_{epoch+1}.pth\", val_results)\n",
    "                \n",
    "                # Learning rate scheduling\n",
    "                self.scheduler.step(val_results['loss'])\n",
    "                \n",
    "                # Early stopping check\n",
    "                if self.optimizer.param_groups[0]['lr'] < 1e-7:\n",
    "                    print(\"ðŸ’¤ Learning rate too small, stopping training\")\n",
    "                    break\n",
    "                \n",
    "        print(f\"Training completed! Best validation accuracy: {self.best_val_acc:.4f}\")\n",
    "        return self.history\n",
    "    \n",
    "    def save_checkpoint(self, epoch, filename, val_results=None):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_val_acc': self.best_val_acc,\n",
    "            'history': self.history,\n",
    "            'dataset_info': self.dataset_info,\n",
    "            'fold_info': self.fold_info\n",
    "        }\n",
    "        \n",
    "        if val_results:\n",
    "            checkpoint['val_results'] = val_results\n",
    "        \n",
    "        checkpoint_path = self.save_dir / filename\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        self.best_model_path = checkpoint_path\n",
    "        print(f\"ðŸ’¾ Saved checkpoint: {checkpoint_path}\")\n",
    "\n",
    "\n",
    "# New K-Fold Training Manager\n",
    "class KFoldIMCTrainer:\n",
    "    \"\"\"Manager for K-Fold cross-validation training\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_factory,  # Function that creates a fresh model for each fold\n",
    "        fold_generator,\n",
    "        dataset_info,\n",
    "        device='cuda' if torch.cuda.is_available() else 'mps',\n",
    "        save_dir='./kfold_results',\n",
    "        **trainer_kwargs  # Additional arguments for IMCTrainer\n",
    "    ):\n",
    "        self.model_factory = model_factory\n",
    "        self.fold_generator = fold_generator\n",
    "        self.dataset_info = dataset_info\n",
    "        self.device = device\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(exist_ok=True)\n",
    "        self.trainer_kwargs = trainer_kwargs\n",
    "        \n",
    "        # Results storage\n",
    "        self.fold_results = []\n",
    "        self.cv_summary = {}\n",
    "        \n",
    "    def train_all_folds(self, num_epochs=50, freeze_backbone_epochs=5):\n",
    "        \"\"\"Train all folds in the cross-validation\"\"\"\n",
    "        \n",
    "        print(f\"ðŸ”„ Starting {self.dataset_info['k_folds']}-Fold Cross-Validation\")\n",
    "        print(f\"ðŸ“Š Dataset: {self.dataset_info['total_samples']} samples, {self.dataset_info['num_classes']} classes\")\n",
    "        print(f\"ðŸ·ï¸ Classes: {self.dataset_info['class_names']}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        fold_results = []\n",
    "        \n",
    "        for fold_idx, (train_loader, val_loader, fold_info) in enumerate(self.fold_generator):\n",
    "            print(f\"\\nðŸŽ¯ FOLD {fold_idx + 1}/{self.dataset_info['k_folds']}\")\n",
    "            print(f\"   Train samples: {fold_info['train_size']}\")\n",
    "            print(f\"   Val samples: {fold_info['val_size']}\")\n",
    "            print(f\"   Train distribution: {fold_info['train_distribution']}\")\n",
    "            print(f\"   Val distribution: {fold_info['val_distribution']}\")\n",
    "            print(\"-\"*60)\n",
    "            \n",
    "            # Create fresh model for this fold\n",
    "            model = self.model_factory().to(self.device)\n",
    "            \n",
    "            # Create fold-specific save directory\n",
    "            fold_save_dir = self.save_dir / f\"fold_{fold_idx + 1}\"\n",
    "            fold_save_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Create trainer for this fold\n",
    "            trainer = IMCTrainer(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                fold_info=fold_info,\n",
    "                dataset_info=self.dataset_info,\n",
    "                device=self.device,\n",
    "                save_dir=fold_save_dir,\n",
    "                **self.trainer_kwargs\n",
    "            )\n",
    "            \n",
    "            # Train this fold\n",
    "            history = trainer.train(\n",
    "                num_epochs=num_epochs,\n",
    "                freeze_backbone_epochs=freeze_backbone_epochs\n",
    "            )\n",
    "            \n",
    "            # Store fold results\n",
    "            fold_result = {\n",
    "                'fold_idx': fold_idx,\n",
    "                'best_val_acc': trainer.best_val_acc,\n",
    "                'history': history,\n",
    "                'fold_info': fold_info,\n",
    "                'best_model_path': trainer.best_model_path\n",
    "            }\n",
    "            fold_results.append(fold_result)\n",
    "            \n",
    "            print(f\"âœ… Fold {fold_idx + 1} completed - Best Val Acc: {trainer.best_val_acc:.4f}\")\n",
    "            \n",
    "            # Clean up GPU memory\n",
    "            del model, trainer\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        self.fold_results = fold_results\n",
    "        self.compute_cv_summary()\n",
    "        self.save_cv_results()\n",
    "        self.plot_cv_results()\n",
    "        \n",
    "        return self.cv_summary\n",
    "    \n",
    "    def compute_cv_summary(self):\n",
    "        \"\"\"Compute cross-validation summary statistics\"\"\"\n",
    "        \n",
    "        # Extract metrics from all folds\n",
    "        val_accuracies = [fold['best_val_acc'] for fold in self.fold_results]\n",
    "        final_train_accs = [fold['history']['train_acc'][-1] for fold in self.fold_results]\n",
    "        final_val_accs = [fold['history']['val_acc'][-1] for fold in self.fold_results]\n",
    "        \n",
    "        # Summary statistics\n",
    "        self.cv_summary = {\n",
    "            'num_folds': len(self.fold_results),\n",
    "            'best_val_accuracies': val_accuracies,\n",
    "            'final_train_accuracies': final_train_accs,\n",
    "            'final_val_accuracies': final_val_accs,\n",
    "            \n",
    "            # Mean and std of best validation accuracies\n",
    "            'mean_val_acc': np.mean(val_accuracies),\n",
    "            'std_val_acc': np.std(val_accuracies),\n",
    "            'min_val_acc': np.min(val_accuracies),\n",
    "            'max_val_acc': np.max(val_accuracies),\n",
    "            \n",
    "            # Overall performance\n",
    "            'mean_final_train_acc': np.mean(final_train_accs),\n",
    "            'mean_final_val_acc': np.mean(final_val_accs),\n",
    "            \n",
    "            # Best fold\n",
    "            'best_fold_idx': np.argmax(val_accuracies),\n",
    "            'best_fold_acc': np.max(val_accuracies)\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ðŸ“ˆ CROSS-VALIDATION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Mean Validation Accuracy: {self.cv_summary['mean_val_acc']:.4f} Â± {self.cv_summary['std_val_acc']:.4f}\")\n",
    "        print(f\"Best Fold: {self.cv_summary['best_fold_idx'] + 1} (Acc: {self.cv_summary['best_fold_acc']:.4f})\")\n",
    "        print(f\"Range: [{self.cv_summary['min_val_acc']:.4f}, {self.cv_summary['max_val_acc']:.4f}]\")\n",
    "        \n",
    "        print(f\"\\nFold-by-fold results:\")\n",
    "        for i, acc in enumerate(val_accuracies):\n",
    "            print(f\"  Fold {i+1}: {acc:.4f}\")\n",
    "    \n",
    "    def save_cv_results(self):\n",
    "        \"\"\"Save cross-validation results\"\"\"\n",
    "        \n",
    "        # Save summary as JSON\n",
    "        summary_path = self.save_dir / 'cv_summary.json'\n",
    "        with open(summary_path, 'w') as f:\n",
    "            # Convert numpy types to native Python types for JSON serialization\n",
    "            json_summary = {}\n",
    "            for key, value in self.cv_summary.items():\n",
    "                if isinstance(value, np.ndarray):\n",
    "                    json_summary[key] = value.tolist()\n",
    "                elif isinstance(value, (np.integer, np.floating)):\n",
    "                    json_summary[key] = value.item()\n",
    "                else:\n",
    "                    json_summary[key] = value\n",
    "            json.dump(json_summary, f, indent=2)\n",
    "        \n",
    "        # Save detailed results\n",
    "        detailed_results = {\n",
    "            'dataset_info': self.dataset_info,\n",
    "            'cv_summary': self.cv_summary,\n",
    "            'fold_results': self.fold_results\n",
    "        }\n",
    "        \n",
    "        results_path = self.save_dir / 'detailed_cv_results.pth'\n",
    "        torch.save(detailed_results, results_path)\n",
    "        \n",
    "        print(f\"ðŸ’¾ Results saved to {self.save_dir}\")\n",
    "    \n",
    "    def plot_cv_results(self):\n",
    "        \"\"\"Plot cross-validation results\"\"\"\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. Validation accuracy across folds\n",
    "        fold_numbers = range(1, len(self.fold_results) + 1)\n",
    "        val_accs = self.cv_summary['best_val_accuracies']\n",
    "        \n",
    "        ax1.bar(fold_numbers, val_accs, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        ax1.axhline(y=self.cv_summary['mean_val_acc'], color='red', linestyle='--', \n",
    "                   label=f\"Mean: {self.cv_summary['mean_val_acc']:.4f}\")\n",
    "        ax1.set_xlabel('Fold')\n",
    "        ax1.set_ylabel('Best Validation Accuracy')\n",
    "        ax1.set_title('Validation Accuracy Across Folds')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Training curves for all folds\n",
    "        for i, fold_result in enumerate(self.fold_results):\n",
    "            epochs = range(1, len(fold_result['history']['val_acc']) + 1)\n",
    "            ax2.plot(epochs, fold_result['history']['val_acc'], \n",
    "                    alpha=0.7, label=f'Fold {i+1}')\n",
    "        \n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Validation Accuracy')\n",
    "        ax2.set_title('Validation Accuracy Curves')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Distribution of final accuracies\n",
    "        ax3.hist(val_accs, bins=min(10, len(val_accs)), alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        ax3.axvline(x=self.cv_summary['mean_val_acc'], color='red', linestyle='--',\n",
    "                   label=f\"Mean: {self.cv_summary['mean_val_acc']:.4f}\")\n",
    "        ax3.set_xlabel('Validation Accuracy')\n",
    "        ax3.set_ylabel('Frequency')\n",
    "        ax3.set_title('Distribution of Best Validation Accuracies')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Summary statistics\n",
    "        ax4.axis('off')\n",
    "        summary_text = f\"\"\"\n",
    "Cross-Validation Summary\n",
    "\n",
    "Number of Folds: {self.cv_summary['num_folds']}\n",
    "Mean Val Accuracy: {self.cv_summary['mean_val_acc']:.4f} Â± {self.cv_summary['std_val_acc']:.4f}\n",
    "\n",
    "Best Fold: {self.cv_summary['best_fold_idx'] + 1}\n",
    "Best Accuracy: {self.cv_summary['best_fold_acc']:.4f}\n",
    "\n",
    "Min Accuracy: {self.cv_summary['min_val_acc']:.4f}\n",
    "Max Accuracy: {self.cv_summary['max_val_acc']:.4f}\n",
    "\n",
    "Dataset: {self.dataset_info['total_samples']} samples\n",
    "Classes: {', '.join(self.dataset_info['class_names'])}\n",
    "        \"\"\"\n",
    "        ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, fontsize=12,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.save_dir / 'cv_results.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Example usage function\n",
    "def train_kfold_imc_model(\n",
    "    data_dir,\n",
    "    model_factory,\n",
    "    k_folds=5,\n",
    "    num_epochs=50,\n",
    "    freeze_backbone_epochs=5,\n",
    "    batch_size=16,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    **dataset_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete K-Fold training pipeline\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to IMC data\n",
    "        model_factory: Function that creates a fresh model (e.g., lambda: create_simple_model())\n",
    "        k_folds: Number of folds\n",
    "        num_epochs: Training epochs per fold\n",
    "        freeze_backbone_epochs: Epochs to train with frozen backbone\n",
    "        batch_size: Batch size\n",
    "        learning_rate: Learning rate\n",
    "        weight_decay: Weight decay\n",
    "        **dataset_kwargs: Additional arguments for IMCDataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import your dataloader functions here\n",
    "   \n",
    "    \n",
    "    # Create k-fold dataloaders\n",
    "    fold_generator, dataset_info = create_kfold_dataloaders(\n",
    "        data_dir=data_dir,\n",
    "        k_folds=k_folds,\n",
    "        batch_size=batch_size,\n",
    "        **dataset_kwargs\n",
    "    )\n",
    "    \n",
    "    # Create K-Fold trainer\n",
    "    kfold_trainer = KFoldIMCTrainer(\n",
    "        model_factory=model_factory,\n",
    "        fold_generator=fold_generator,\n",
    "        dataset_info=dataset_info,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        save_dir=f'./kfold_results_{k_folds}fold'\n",
    "    )\n",
    "    \n",
    "    # Train all folds\n",
    "    cv_summary = kfold_trainer.train_all_folds(\n",
    "        num_epochs=num_epochs,\n",
    "        freeze_backbone_epochs=freeze_backbone_epochs\n",
    "    )\n",
    "    \n",
    "    return cv_summary, kfold_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a46901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "Loading data for k-fold cross-validation...\n",
      " Class distribution: {'Malignant': 55, 'Benign': 8}\n",
      " Using stratified 5-fold cross-validation\n",
      "ðŸ“Š K-Fold Dataset Summary:\n",
      "   Classification task: condition\n",
      "   Classes: ['Benign', 'Malignant']\n",
      "   Total samples: 63\n",
      "   Number of folds: 5\n",
      " Dataset Info:\n",
      "   Classes: ['Benign', 'Malignant']\n",
      "   Total samples: 63\n",
      "   K-folds: 5\n",
      "\n",
      " Starting 5-Fold Cross-Validation...\n",
      "\n",
      " Fold 1/5\n",
      "   Train samples: 50\n",
      "   Val samples: 13\n",
      "   Train distribution: {'Malignant': 44, 'Benign': 6}\n",
      "   Val distribution: {'Benign': 2, 'Malignant': 11}\n",
      "\n",
      "============================================================\n",
      " FOLD 1/5\n",
      "============================================================\n",
      "Train samples: 50\n",
      "Val samples: 13\n",
      "Train distribution: {'Malignant': 44, 'Benign': 6}\n",
      "Val distribution: {'Benign': 2, 'Malignant': 11}\n",
      "Using EfficientNet-B3 backbone (pretrained=True)\n",
      "Simple Model Summary\n",
      "Markers: 62, Backbone: EfficientNet-B3, pretrained: True\n",
      "Feature_dim: 128, classes: 2, device: cuda\n",
      "Dropout rate: 0.6\n",
      "Total parameters: 11,601,050\n",
      "Trainable parameters: 11,601,050\n",
      "Using class weights: tensor([4.1667, 0.5682], device='cuda:0')\n",
      "Using mixed precision training\n",
      " Starting training for fold 1...\n",
      "Starting training for 30 epochs\n",
      "First 5 epochs with frozen backbone\n",
      "Training fusion head only 5 epochs\n",
      "Frozen backbone - only training fusion head\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/16 [00:00<?, ?it/s]/tmp/ipykernel_26110/2136768688.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training:   6%|â–‹         | 1/16 [00:09<02:17,  9.16s/it, Loss=0.6219, Acc=0.6667]/tmp/ipykernel_26110/2136768688.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training:  12%|â–ˆâ–Ž        | 2/16 [00:10<01:04,  4.61s/it, Loss=0.8941, Acc=0.6667]/tmp/ipykernel_26110/2136768688.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training:  19%|â–ˆâ–‰        | 3/16 [00:12<00:42,  3.23s/it, Loss=0.6533, Acc=0.6667]/tmp/ipykernel_26110/2136768688.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:13<00:31,  2.60s/it, Loss=0.4409, Acc=0.7500]/tmp/ipykernel_26110/2136768688.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:14<00:42,  3.57s/it, Loss=0.4409, Acc=0.7500]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Starting training for fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     history = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_epochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfreeze_backbone_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfreeze_backbone_epochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     \u001b[38;5;66;03m# Store fold results\u001b[39;00m\n\u001b[32m    111\u001b[39m     fold_result = {\n\u001b[32m    112\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfold_idx\u001b[39m\u001b[33m'\u001b[39m: fold_idx,\n\u001b[32m    113\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mbest_val_acc\u001b[39m\u001b[33m'\u001b[39m: trainer.best_val_acc,\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mconvergence_epoch\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(history[\u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m history[\u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    122\u001b[39m     }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 184\u001b[39m, in \u001b[36mIMCTrainer.train\u001b[39m\u001b[34m(self, num_epochs, freeze_backbone_epochs)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfreeze_backbone_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Train \u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m train_loss, train_acc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m    187\u001b[39m val_results = \u001b[38;5;28mself\u001b[39m.validate_epoch()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mIMCTrainer.train_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_mixed_precision:\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m         output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m         loss = \u001b[38;5;28mself\u001b[39m.criterion(output[\u001b[33m'\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m'\u001b[39m], labels)\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mself\u001b[39m.scaler.scale(loss).backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 153\u001b[39m, in \u001b[36mSimpleIMCClassifier.forward\u001b[39m\u001b[34m(self, imc_data)\u001b[39m\n\u001b[32m    151\u001b[39m marker_data = imc_data[:, i:i+\u001b[32m1\u001b[39m, :, :]\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.shared_backbone:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmarker_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Not implemented\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mEfficientNetMarkerEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# x shape: [batch_size, 1, H, W]\u001b[39;00m\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# Extract features from backbone (before classifier)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, 1792, H', W']\u001b[39;00m\n\u001b[32m     65\u001b[39m     features = \u001b[38;5;28mself\u001b[39m.avgpool(features)  \u001b[38;5;66;03m# [batch_size, 1792, 1, 1]\u001b[39;00m\n\u001b[32m     66\u001b[39m     features = \u001b[38;5;28mself\u001b[39m.flatten(features)  \u001b[38;5;66;03m# [batch_size, 1792]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torchvision/models/efficientnet.py:164\u001b[39m, in \u001b[36mMBConv.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_res_connect:\n\u001b[32m    166\u001b[39m         result = \u001b[38;5;28mself\u001b[39m.stochastic_depth(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Utkarsh/IMC_classifier/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2822\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2820\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'batch_size': 3,\n",
    "    'image_size': (256, 256),\n",
    "    'k_folds': 5,\n",
    "    'num_epochs': 30,\n",
    "    'freeze_backbone_epochs': 5,\n",
    "    'learning_rate': 1e-3,  # Fixed from your original\n",
    "    'weight_decay': 1e-4,   # Fixed from your original\n",
    "    'feature_dim': 128,\n",
    "    'dropout_rate': 0.6,\n",
    "    'num_workers': 4,\n",
    "    'random_seed': 17025\n",
    "}\n",
    "\n",
    "print(\"Loading data for k-fold cross-validation...\")\n",
    "\n",
    "# Create k-fold dataloaders\n",
    "fold_generator, dataset_info = create_kfold_dataloaders(\n",
    "    data_dir='./data',\n",
    "    k_folds=config['k_folds'],\n",
    "    classification_task='condition',\n",
    "    batch_size=config['batch_size'],\n",
    "    image_size=config['image_size'],\n",
    "    arcsinh_transform=True,\n",
    "    cofactor=5.0,\n",
    "    num_workers=config['num_workers'],\n",
    "    random_seed=config['random_seed']\n",
    ")\n",
    "\n",
    "print(f\" Dataset Info:\")\n",
    "print(f\"   Classes: {dataset_info['class_names']}\")\n",
    "print(f\"   Total samples: {dataset_info['total_samples']}\")\n",
    "print(f\"   K-folds: {dataset_info['k_folds']}\")\n",
    "\n",
    "# Storage for cross-validation results\n",
    "cv_results = {\n",
    "    'fold_results': [],\n",
    "    'fold_histories': [],\n",
    "    'best_models': [],\n",
    "    'dataset_info': dataset_info,\n",
    "    'config': config\n",
    "}\n",
    "\n",
    "# Aggregate metrics across folds\n",
    "aggregate_metrics = defaultdict(list)\n",
    "\n",
    "print(f\"\\n Starting {config['k_folds']}-Fold Cross-Validation...\")\n",
    "\n",
    "# Train on each fold\n",
    "for fold_idx, (train_loader, val_loader, fold_info) in enumerate(fold_generator):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" FOLD {fold_idx + 1}/{config['k_folds']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Train samples: {fold_info['train_size']}\")\n",
    "    print(f\"Val samples: {fold_info['val_size']}\")\n",
    "    print(f\"Train distribution: {fold_info['train_distribution']}\")\n",
    "    print(f\"Val distribution: {fold_info['val_distribution']}\")\n",
    "    \n",
    "    # Create model for this fold\n",
    "    model = create_simple_model(  # Fixed function name\n",
    "        num_markers=62,\n",
    "        num_classes=dataset_info['num_classes'],\n",
    "        pretrained=True,\n",
    "        shared_backbone=True,\n",
    "        feature_dim=config['feature_dim'],\n",
    "        dropout_rate=config['dropout_rate'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Create fold-specific save directory\n",
    "    fold_save_dir = f'./checkpoints/fold_{fold_idx + 1}'\n",
    "    Path(fold_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create trainer for this fold\n",
    "    trainer = IMCTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        fold_info=fold_info,  # Pass fold_info directly\n",
    "        dataset_info=dataset_info,\n",
    "        device=device,\n",
    "        learning_rate=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "        use_class_weights=True,\n",
    "        use_mixed_precision=True,\n",
    "        save_dir=fold_save_dir\n",
    "    )\n",
    "    \n",
    "    # Train model for this fold\n",
    "    print(f\" Starting training for fold {fold_idx + 1}...\")\n",
    "    try:\n",
    "        history = trainer.train(\n",
    "            num_epochs=config['num_epochs'],\n",
    "            freeze_backbone_epochs=config['freeze_backbone_epochs']\n",
    "        )\n",
    "        \n",
    "        # Store fold results\n",
    "        fold_result = {\n",
    "            'fold_idx': fold_idx,\n",
    "            'best_val_acc': trainer.best_val_acc,\n",
    "            'final_train_acc': history['train_acc'][-1] if history['train_acc'] else 0,\n",
    "            'final_val_acc': history['val_acc'][-1] if history['val_acc'] else 0,\n",
    "            'final_train_loss': history['train_loss'][-1] if history['train_loss'] else float('inf'),\n",
    "            'final_val_loss': history['val_loss'][-1] if history['val_loss'] else float('inf'),\n",
    "            'best_val_loss': min(history['val_loss']) if history['val_loss'] else float('inf'),\n",
    "            'fold_info': fold_info,\n",
    "            'best_model_path': str(trainer.best_model_path) if trainer.best_model_path else None,\n",
    "            'convergence_epoch': len(history['val_acc']) if history['val_acc'] else 0\n",
    "        }\n",
    "        \n",
    "        # Store results\n",
    "        cv_results['fold_results'].append(fold_result)\n",
    "        cv_results['fold_histories'].append(history)\n",
    "        cv_results['best_models'].append(trainer.best_model_path)\n",
    "        \n",
    "        # Aggregate metrics\n",
    "        aggregate_metrics['val_acc'].append(trainer.best_val_acc)\n",
    "        aggregate_metrics['final_train_acc'].append(fold_result['final_train_acc'])\n",
    "        aggregate_metrics['final_val_acc'].append(fold_result['final_val_acc'])\n",
    "        aggregate_metrics['final_train_loss'].append(fold_result['final_train_loss'])\n",
    "        aggregate_metrics['final_val_loss'].append(fold_result['final_val_loss'])\n",
    "        aggregate_metrics['best_val_loss'].append(fold_result['best_val_loss'])\n",
    "        aggregate_metrics['convergence_epochs'].append(fold_result['convergence_epoch'])\n",
    "        \n",
    "        # Plot training history for this fold\n",
    "        trainer.plot_training_history()\n",
    "        \n",
    "        # Save fold-specific results\n",
    "        fold_results_path = Path(fold_save_dir) / 'fold_results.json'\n",
    "        \n",
    "        with open(fold_results_path, 'w') as f:\n",
    "            # Convert tensors and Paths to serializable format\n",
    "            serializable_result = {}\n",
    "            for k, v in fold_result.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    serializable_result[k] = v.tolist()\n",
    "                elif isinstance(v, Path):\n",
    "                    serializable_result[k] = str(v)\n",
    "                elif k == 'fold_info':\n",
    "                    # Handle fold_info specially\n",
    "                    serializable_fold_info = {}\n",
    "                    for fk, fv in v.items():\n",
    "                        if isinstance(fv, torch.Tensor):\n",
    "                            serializable_fold_info[fk] = fv.tolist()\n",
    "                        else:\n",
    "                            serializable_fold_info[fk] = fv\n",
    "                    serializable_result[k] = serializable_fold_info\n",
    "                else:\n",
    "                    serializable_result[k] = v\n",
    "            json.dump(serializable_result, f, indent=2)\n",
    "        \n",
    "        print(f\" Fold {fold_idx + 1} completed!\")\n",
    "        print(f\"   Best Val Accuracy: {trainer.best_val_acc:.4f}\")\n",
    "        print(f\"   Final Train Accuracy: {fold_result['final_train_acc']:.4f}\")\n",
    "        print(f\"   Final Val Accuracy: {fold_result['final_val_acc']:.4f}\")\n",
    "        print(f\"   Convergence Epoch: {fold_result['convergence_epoch']}\")\n",
    "        print(f\"   Results saved to: {fold_results_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error in fold {fold_idx + 1}: {str(e)}\")\n",
    "        # Store failed fold info\n",
    "        failed_result = {\n",
    "            'fold_idx': fold_idx,\n",
    "            'error': str(e),\n",
    "            'fold_info': fold_info\n",
    "        }\n",
    "        cv_results['fold_results'].append(failed_result)\n",
    "        continue\n",
    "    \n",
    "    finally:\n",
    "        # Clean up model to free memory\n",
    "        del model, trainer\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Check if we have any successful folds\n",
    "successful_folds = [r for r in cv_results['fold_results'] if 'best_val_acc' in r]\n",
    "\n",
    "if not successful_folds:\n",
    "    print(\" No folds completed successfully!\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\" CROSS-VALIDATION RESULTS SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Successful folds: {len(successful_folds)}/{config['k_folds']}\")\n",
    "\n",
    "# Calculate means and standard deviations\n",
    "def safe_mean_std(values):\n",
    "    \"\"\"Calculate mean and std, handling empty lists\"\"\"\n",
    "    if not values:\n",
    "        return 0.0, 0.0\n",
    "    return np.mean(values), np.std(values)\n",
    "\n",
    "mean_val_acc, std_val_acc = safe_mean_std(aggregate_metrics['val_acc'])\n",
    "mean_train_acc, std_train_acc = safe_mean_std(aggregate_metrics['final_train_acc'])\n",
    "mean_final_val_acc, std_final_val_acc = safe_mean_std(aggregate_metrics['final_val_acc'])\n",
    "mean_val_loss, std_val_loss = safe_mean_std(aggregate_metrics['best_val_loss'])\n",
    "mean_convergence, std_convergence = safe_mean_std(aggregate_metrics['convergence_epochs'])\n",
    "\n",
    "print(f\"\\nðŸ“Š Performance Metrics:\")\n",
    "print(f\"Best Validation Accuracy: {mean_val_acc:.4f} Â± {std_val_acc:.4f}\")\n",
    "print(f\"Final Training Accuracy: {mean_train_acc:.4f} Â± {std_train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {mean_final_val_acc:.4f} Â± {std_final_val_acc:.4f}\")\n",
    "print(f\"Best Validation Loss: {mean_val_loss:.4f} Â± {std_val_loss:.4f}\")\n",
    "print(f\"Convergence Epochs: {mean_convergence:.1f} Â± {std_convergence:.1f}\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Per-fold results:\")\n",
    "for result in successful_folds:\n",
    "    i = result['fold_idx']\n",
    "    print(f\"  Fold {i+1}: Val Acc = {result['best_val_acc']:.4f}, \"\n",
    "          f\"Final Val Acc = {result['final_val_acc']:.4f}, \"\n",
    "          f\"Epochs = {result['convergence_epoch']}\")\n",
    "\n",
    "# Find best performing fold\n",
    "if aggregate_metrics['val_acc']:\n",
    "    best_fold_idx = np.argmax(aggregate_metrics['val_acc'])\n",
    "    best_fold = successful_folds[best_fold_idx]\n",
    "    print(f\"\\n Best performing fold: Fold {best_fold['fold_idx'] + 1}\")\n",
    "    print(f\"   Best validation accuracy: {best_fold['best_val_acc']:.4f}\")\n",
    "    print(f\"   Model path: {best_fold['best_model_path']}\")\n",
    "\n",
    "def plot_comprehensive_cv_results(cv_results, aggregate_metrics, config):\n",
    "    \"\"\"Plot comprehensive cross-validation results\"\"\"\n",
    "    \n",
    "    # Filter successful results\n",
    "    successful_results = [r for r in cv_results['fold_results'] if 'best_val_acc' in r]\n",
    "    successful_histories = [cv_results['fold_histories'][r['fold_idx']] for r in successful_results]\n",
    "    \n",
    "    if not successful_results:\n",
    "        print(\"No successful results to plot!\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'{config[\"k_folds\"]}-Fold Cross-Validation Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Validation accuracy per fold\n",
    "    fold_nums = [r['fold_idx'] + 1 for r in successful_results]\n",
    "    val_accs = [r['best_val_acc'] for r in successful_results]\n",
    "    \n",
    "    axes[0, 0].bar([f\"Fold {i}\" for i in fold_nums], val_accs, alpha=0.7, color='skyblue')\n",
    "    if val_accs:\n",
    "        axes[0, 0].axhline(y=np.mean(val_accs), color='red', \n",
    "                           linestyle='--', label=f\"Mean: {np.mean(val_accs):.3f}\")\n",
    "    axes[0, 0].set_title('Best Validation Accuracy by Fold')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Training curves for all folds\n",
    "    for i, history in enumerate(successful_histories):\n",
    "        if history['val_acc']:\n",
    "            epochs = range(1, len(history['val_acc']) + 1)\n",
    "            fold_idx = successful_results[i]['fold_idx']\n",
    "            axes[0, 1].plot(epochs, history['val_acc'], alpha=0.7, label=f'Fold {fold_idx+1}')\n",
    "    axes[0, 1].set_title('Validation Accuracy Curves')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Loss curves for all folds\n",
    "    for i, history in enumerate(successful_histories):\n",
    "        if history['val_loss']:\n",
    "            epochs = range(1, len(history['val_loss']) + 1)\n",
    "            fold_idx = successful_results[i]['fold_idx']\n",
    "            axes[0, 2].plot(epochs, history['val_loss'], alpha=0.7, label=f'Fold {fold_idx+1}')\n",
    "    axes[0, 2].set_title('Validation Loss Curves')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Loss')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Box plot of metrics\n",
    "    metrics_data = []\n",
    "    metrics_labels = []\n",
    "    \n",
    "    if aggregate_metrics['val_acc']:\n",
    "        metrics_data.append(aggregate_metrics['val_acc'])\n",
    "        metrics_labels.append('Best Val Acc')\n",
    "    \n",
    "    if aggregate_metrics['final_val_acc']:\n",
    "        metrics_data.append(aggregate_metrics['final_val_acc'])\n",
    "        metrics_labels.append('Final Val Acc')\n",
    "    \n",
    "    if aggregate_metrics['final_train_acc']:\n",
    "        metrics_data.append(aggregate_metrics['final_train_acc'])\n",
    "        metrics_labels.append('Final Train Acc')\n",
    "    \n",
    "    if metrics_data:\n",
    "        axes[1, 0].boxplot(metrics_data, labels=metrics_labels)\n",
    "        axes[1, 0].set_title('Accuracy Distribution')\n",
    "        axes[1, 0].set_ylabel('Accuracy')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 5. Convergence analysis\n",
    "    if aggregate_metrics['convergence_epochs']:\n",
    "        convergence_epochs = aggregate_metrics['convergence_epochs']\n",
    "        axes[1, 1].bar([f\"Fold {i+1}\" for i in fold_nums], \n",
    "                       [successful_results[i]['convergence_epoch'] for i in range(len(successful_results))],\n",
    "                       alpha=0.7, color='lightgreen')\n",
    "        axes[1, 1].axhline(y=np.mean(convergence_epochs), color='red', \n",
    "                           linestyle='--', label=f\"Mean: {np.mean(convergence_epochs):.1f}\")\n",
    "        axes[1, 1].set_title('Training Epochs per Fold')\n",
    "        axes[1, 1].set_ylabel('Epochs')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 6. Performance summary\n",
    "    axes[1, 2].axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "Cross-Validation Summary\n",
    "\n",
    "Successful Folds: {len(successful_results)}/{config['k_folds']}\n",
    "Dataset: {cv_results['dataset_info']['total_samples']} samples\n",
    "Classes: {', '.join(cv_results['dataset_info']['class_names'])}\n",
    "\n",
    "Mean Val Accuracy: {mean_val_acc:.4f} Â± {std_val_acc:.4f}\n",
    "Mean Train Accuracy: {mean_train_acc:.4f} Â± {std_train_acc:.4f}\n",
    "\n",
    "Best Fold: {best_fold['fold_idx'] + 1 if 'best_fold' in locals() else 'N/A'}\n",
    "Best Accuracy: {best_fold['best_val_acc']:.4f if 'best_fold' in locals() else 'N/A'}\n",
    "\n",
    "Configuration:\n",
    "- Epochs: {config['num_epochs']}\n",
    "- Frozen Epochs: {config['freeze_backbone_epochs']}\n",
    "- Batch Size: {config['batch_size']}\n",
    "- Learning Rate: {config['learning_rate']}\n",
    "    \"\"\"\n",
    "    \n",
    "    axes[1, 2].text(0.05, 0.95, summary_text, transform=axes[1, 2].transAxes, \n",
    "                    fontsize=10, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = Path('./checkpoints') / 'cv_comprehensive_results.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\" Cross-validation plots saved to: {plot_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Create and show the comprehensive plot\n",
    "if successful_folds:\n",
    "    plot_comprehensive_cv_results(cv_results, aggregate_metrics, config)\n",
    "\n",
    "# Save comprehensive cross-validation results\n",
    "final_cv_results = {\n",
    "    'summary_statistics': {\n",
    "        'successful_folds': len(successful_folds),\n",
    "        'total_folds': config['k_folds'],\n",
    "        'mean_val_acc': mean_val_acc,\n",
    "        'std_val_acc': std_val_acc,\n",
    "        'mean_train_acc': mean_train_acc,\n",
    "        'std_train_acc': std_train_acc,\n",
    "        'mean_final_val_acc': mean_final_val_acc,\n",
    "        'std_final_val_acc': std_final_val_acc,\n",
    "        'mean_val_loss': mean_val_loss,\n",
    "        'std_val_loss': std_val_loss,\n",
    "        'mean_convergence_epochs': mean_convergence,\n",
    "        'std_convergence_epochs': std_convergence,\n",
    "    },\n",
    "    'per_fold_results': cv_results['fold_results'],\n",
    "    'aggregate_metrics': {k: v for k, v in aggregate_metrics.items()},\n",
    "    'dataset_info': {k: v.tolist() if isinstance(v, torch.Tensor) else v \n",
    "                     for k, v in dataset_info.items()},\n",
    "    'config': config\n",
    "}\n",
    "\n",
    "# Add best fold info if available\n",
    "if 'best_fold' in locals():\n",
    "    final_cv_results['summary_statistics']['best_fold'] = best_fold['fold_idx'] + 1\n",
    "    final_cv_results['summary_statistics']['best_fold_acc'] = best_fold['best_val_acc']\n",
    "    final_cv_results['best_model_path'] = best_fold['best_model_path']\n",
    "\n",
    "# Save final results\n",
    "final_results_path = Path('./checkpoints') / 'cv_final_results.json'\n",
    "final_results_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(final_results_path, 'w') as f:\n",
    "    json.dump(final_cv_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n Final cross-validation results saved to: {final_results_path}\")\n",
    "\n",
    "if 'best_fold' in locals():\n",
    "    print(f\"Best model from Fold {best_fold['fold_idx'] + 1}: {best_fold['best_model_path']}\")\n",
    "    print(f\" Overall performance: {mean_val_acc:.4f} Â± {std_val_acc:.4f}\")\n",
    "    \n",
    "    # Instructions for using the best model\n",
    "    print(f\"\\n To use the best model for inference:\")\n",
    "    print(f\"```python\")\n",
    "    print(f\"import torch\")\n",
    "    print(f\"from your_model_module import create_simple_model\")\n",
    "    print(f\"\")\n",
    "    print(f\"# Load the best model\")\n",
    "    print(f\"device = '{device}'\")\n",
    "    print(f\"model = create_simple_model(num_markers=62, num_classes={dataset_info['num_classes']}, device=device)\")\n",
    "    print(f\"checkpoint = torch.load('{best_fold['best_model_path']}', map_location=device)\")\n",
    "    print(f\"model.load_state_dict(checkpoint['model_state_dict'])\")\n",
    "    print(f\"model.eval()\")\n",
    "    print(f\"```\")\n",
    "else:\n",
    "    print(\" No successful folds completed!\")\n",
    "\n",
    "print(f\"\\n K-Fold Cross-Validation Complete!\")\n",
    "print(f\"Check the './checkpoints' directory for detailed results and model files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb162b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Checking and fixing sample data types...\n",
      "Sample 0:\n",
      "  tissue: <class 'str'> = LIVER\n",
      "  condition: <class 'str'> = Malignant\n",
      "Sample 1:\n",
      "  tissue: <class 'str'> = PROSTATE\n",
      "  condition: <class 'str'> = Malignant\n",
      "Sample 2:\n",
      "  tissue: <class 'str'> = PROSTATE\n",
      "  condition: <class 'str'> = Malignant\n",
      "âœ… Fixed sample data types\n"
     ]
    }
   ],
   "source": [
    "# Quick fix - add this after create_kfold_dataloaders\n",
    "print(\"ðŸ”§ Checking and fixing sample data types...\")\n",
    "\n",
    "# Get the full dataset to inspect it\n",
    "full_dataset = IMCDataset(\n",
    "    data_dir='./data',\n",
    "    classification_task='condition'\n",
    ")\n",
    "\n",
    "# Debug the first few samples\n",
    "for i, sample in enumerate(full_dataset.samples[:3]):\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"  tissue: {type(sample['tissue'])} = {sample['tissue']}\")\n",
    "    print(f\"  condition: {type(sample['condition'])} = {sample['condition']}\")\n",
    "\n",
    "# Fix any array issues\n",
    "for sample in full_dataset.samples:\n",
    "    if isinstance(sample['tissue'], (list, tuple, np.ndarray)):\n",
    "        sample['tissue'] = str(sample['tissue'][0]) if len(sample['tissue']) > 0 else \"unknown\"\n",
    "    if isinstance(sample['condition'], (list, tuple, np.ndarray)):\n",
    "        sample['condition'] = str(sample['condition'][0]) if len(sample['condition']) > 0 else \"unknown\"\n",
    "    \n",
    "    # Ensure they're strings\n",
    "    sample['tissue'] = str(sample['tissue'])\n",
    "    sample['condition'] = str(sample['condition'])\n",
    "\n",
    "print(\"âœ… Fixed sample data types\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
